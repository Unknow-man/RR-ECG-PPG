{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# data = pickle.load(open('../data/leftppgecg.p','rb'))\n",
    "directory = '../data_users/ecg_ppg/'\n",
    "dfs = []\n",
    "for f in os.listdir(directory)[:20]:\n",
    "    if f[-1]!='p':\n",
    "        continue\n",
    "    a = pickle.load(open(directory+f,'rb'))\n",
    "    print(a.shape,end=',')\n",
    "    dfs.append(a)\n",
    "print()\n",
    "data1 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "data_all = deepcopy(data1)\n",
    "\n",
    "data_all['red_rr'] = data_all['ppg_rr'].apply(lambda x:x[0])\n",
    "data_all['ir_rr'] = data_all['ppg_rr'].apply(lambda x:x[1])\n",
    "data_all['green_rr'] = data_all['ppg_rr'].apply(lambda x:x[2])\n",
    "data_all['red_qual'] = data_all['likelihood'].apply(lambda x:x[0])\n",
    "data_all['ir_qual'] = data_all['likelihood'].apply(lambda x:x[1])\n",
    "data_all['green_qual'] = data_all['likelihood'].apply(lambda x:x[2])\n",
    "data_all['index'] = data_all['likelihood'].apply(lambda x:np.argmax(np.array(x)))\n",
    "values = data_all[['ppg_rr','index']].values\n",
    "values = [a[b] for a,b in values]\n",
    "data_all['ppg_rr_best'] = values\n",
    "data_all['likelihood_best'] = data_all['likelihood'].apply(lambda x:max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_all,open('../data_users/merged_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "data_all = pickle.load(open('../data_users/merged_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "def get_data1(a):\n",
    "    features = []\n",
    "    ecg_rr = a[:,-1]\n",
    "    if len(ecg_rr[np.isnan(ecg_rr)])>20:\n",
    "        return [],[],[],[],[],[]\n",
    "    ecg_rr[np.isnan(ecg_rr)] = 0\n",
    "    m = np.nanmean(ecg_rr[ecg_rr>0])\n",
    "    s = np.nanmean(ecg_rr[ecg_rr>0])\n",
    "    if len(ecg_rr)<60:\n",
    "        return [],[],[],[],[],[]\n",
    "    y = []\n",
    "    X = []\n",
    "    ecg = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    quals = []\n",
    "    for i in [-2]:\n",
    "        ppg_rr = a[:,i]\n",
    "        ppg_qual = a[:,i-4]\n",
    "        index1 = ~np.isnan(ppg_rr)\n",
    "        if len(ppg_rr[index1])<50:\n",
    "            continue\n",
    "        index = np.isnan(ppg_rr)\n",
    "        ppg_qual[index] = -1\n",
    "        tmp = a[:,np.array([-2,-3,-4,-5,-6,-7,-8,-9,1])].reshape(60,9)\n",
    "        tmp[np.isnan(tmp[:,0]),0] = np.nanmean(tmp[~np.isnan(tmp[:,0]),0])\n",
    "        tmp[tmp[:,0]==0,0] = np.mean(tmp[tmp[:,0]>0,0])\n",
    "        tmp[np.isnan(tmp)] = 0\n",
    "        y.append(tmp[:,0].reshape(1,60,1))\n",
    "        X.append(tmp.reshape(1,60,9))\n",
    "        means.append(m)\n",
    "        stds.append(s)\n",
    "        ecg.append(ecg_rr.reshape(1,60,1))\n",
    "        quals.append(ppg_qual.reshape(1,60,1))\n",
    "    return X,y,ecg,means,stds,quals\n",
    "\n",
    "unique_users = data_all['user'].unique()\n",
    "\n",
    "def get_data(name,df):\n",
    "    df = df[['time','activity','red_qual','ir_qual','green_qual','likelihood_best',\n",
    "             'red_rr','ir_rr','green_rr','ppg_rr_best','ecg_rr']].values\n",
    "    return df.reshape(-1,60,11)\n",
    "def get_all_data(data_user):\n",
    "    data_user.set_index('timestamp',inplace=True)\n",
    "    convert_dict = {'ecg_rr': float}\n",
    "    data_user = data_user.astype(convert_dict) \n",
    "    data_resampled = data_user.resample('1S').mean()\n",
    "    if 'ecg_rr' not in np.array(data_resampled.columns.values):\n",
    "        return []\n",
    "    df_col = [get_data(group_name, df_group) for group_name, df_group\n",
    "                                           in data_resampled.groupby(pd.Grouper(freq='60S')) if df_group.shape[0]==60]\n",
    "    df_user = np.concatenate(df_col)\n",
    "    df_col = [get_data1(a) for a in df_user if len(a[~np.isnan(a[:,-1]),-1])>20]\n",
    "    return df_col\n",
    "# for user in unique_users:\n",
    "#     data_user = data_all[data_all.user.isin([user])]\n",
    "all_X = Parallel(n_jobs=20,verbose=3)(delayed(get_all_data)(data_all[data_all.user.isin([user])]) for user in unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = [],[],[],[],[],[]\n",
    "for i,b in enumerate(all_X):\n",
    "    if len(b)==0:\n",
    "        continue\n",
    "    for a in b:\n",
    "        X.extend(a[0])\n",
    "        y.extend(a[1])\n",
    "        ecg.extend(a[2])\n",
    "        means.extend(a[3])\n",
    "        stds.extend(a[4])\n",
    "        quals.extend(a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([X,y,ecg,means,stds,quals],open('../data_users/processed_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "X,y,ecg,means,stds,quals = pickle.load(open('../data_users/processed_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = np.concatenate(X),np.concatenate(y).reshape(-1,60),np.concatenate(ecg).reshape(-1,60),\\\n",
    "np.array(means).reshape(-1,1),np.array(stds).reshape(-1,1),np.concatenate(quals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32330, 60, 13) (19905, 60) (8083, 60) (8083, 1) (8083, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector,Bidirectional,Multiply,multiply,Permute,Conv1D,Dropout,BatchNormalization\n",
    "from keras.layers import TimeDistributed,Dense,Flatten,Reshape,Lambda,Activation,GRU,MaxPool1D,concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras import metrics,losses\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "X_train, X_test, y_train, y_test,ecg_train, \\\n",
    "ecg_test,means_train,means_test,stds_train,stds_test, \\\n",
    "quals_train,quals_test= train_test_split(\n",
    "    X[:,:,np.array([0,4,8,1,5,8,2,6,8,3,7,8,8])], y,ecg,means,stds,quals, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val,means_train,means_val,stds_train,stds_val = train_test_split(\n",
    "    X_train, y_train,means_train,stds_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_test.shape,y_val.shape,means_val.shape,stds_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 60, 13)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 60, 3)        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 60, 3)        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 60, 3)        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 60, 3)        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_47 (Bidirectional (None, 60, 120)      23040       lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_48 (Bidirectional (None, 60, 120)      23040       lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_49 (Bidirectional (None, 60, 120)      23040       lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_50 (Bidirectional (None, 60, 120)      23040       lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 60, 1)        121         bidirectional_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 60, 1)        121         bidirectional_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 60, 1)        121         bidirectional_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 60, 1)        121         bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 60)           0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_56 (Flatten)            (None, 60)           0           dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 60)           0           dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_58 (Flatten)            (None, 60)           0           dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 60)           0           flatten_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 60)           0           flatten_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 60)           0           flatten_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 60)           0           flatten_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 60, 1)        0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 60, 1)        0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 60, 1)        0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 60, 1)        0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 60, 1)        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention (Concatenate)         (None, 60, 5)        0           reshape_29[0][0]                 \n",
      "                                                                 reshape_30[0][0]                 \n",
      "                                                                 reshape_31[0][0]                 \n",
      "                                                                 reshape_32[0][0]                 \n",
      "                                                                 lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 60, 1)        6           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_50 (RepeatVector) (None, 120, 60)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_51 (RepeatVector) (None, 120, 60)      0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_52 (RepeatVector) (None, 120, 60)      0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_53 (RepeatVector) (None, 120, 60)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 60)           0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_50 (Permute)            (None, 60, 120)      0           repeat_vector_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "permute_51 (Permute)            (None, 60, 120)      0           repeat_vector_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "permute_52 (Permute)            (None, 60, 120)      0           repeat_vector_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "permute_53 (Permute)            (None, 60, 120)      0           repeat_vector_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 60)           0           flatten_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 60, 120)      0           permute_50[0][0]                 \n",
      "                                                                 bidirectional_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 60, 120)      0           permute_51[0][0]                 \n",
      "                                                                 bidirectional_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 60, 120)      0           permute_52[0][0]                 \n",
      "                                                                 bidirectional_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 60, 120)      0           permute_53[0][0]                 \n",
      "                                                                 bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_54 (RepeatVector) (None, 120, 60)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Concatenate)            (None, 60, 480)      0           multiply_50[0][0]                \n",
      "                                                                 multiply_51[0][0]                \n",
      "                                                                 multiply_52[0][0]                \n",
      "                                                                 multiply_53[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "permute_54 (Permute)            (None, 60, 120)      0           repeat_vector_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_51 (Bidirectional (None, 60, 120)      194760      output[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 60, 120)      0           permute_54[0][0]                 \n",
      "                                                                 bidirectional_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 60, 10)       1210        multiply_54[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 600)          0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequence1 (Dense)               (None, 30)           18030       flatten_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequence (Dense)                (None, 60)           1860        sequence1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 308,510\n",
      "Trainable params: 308,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = 60\n",
    "input_dim = 13\n",
    "latent_dim = 20\n",
    "output_dim = 1\n",
    "n = 1\n",
    "input_shape = (timesteps,input_dim)\n",
    "act = 'relu'\n",
    "\n",
    "def get_attention(input_1,timesteps):\n",
    "    encoded = Bidirectional(GRU(timesteps,return_sequences=True,activation='relu',go_backwards=True))(input_1)\n",
    "    att = Dense(1,activation='relu')(encoded)\n",
    "    att = Flatten()(att)\n",
    "    att1 = Activation(activation=\"softmax\")(att)\n",
    "    att = RepeatVector(timesteps*2)(att1)\n",
    "    att = Permute((2,1))(att)\n",
    "    mer = multiply([att, encoded])\n",
    "    return mer,Reshape((timesteps,1))(att1)\n",
    "\n",
    "def crop(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func)\n",
    "    \n",
    "    \n",
    "inputs = Input(shape=input_shape)\n",
    "input_best = crop(2,0,3)(inputs)\n",
    "input_red = crop(2,3,6)(inputs)\n",
    "input_ir = crop(2,6,9)(inputs)\n",
    "input_green = crop(2,9,12)(inputs)\n",
    "motion = crop(2,12,13)(inputs)\n",
    "\n",
    "output_best,at_best = get_attention(input_best,timesteps)\n",
    "output_red,at_red = get_attention(input_red,timesteps)\n",
    "output_ir,at_ir = get_attention(input_ir,timesteps)\n",
    "output_green,at_green = get_attention(input_green,timesteps)\n",
    "\n",
    "at_all = concatenate([at_best,at_red,at_ir,at_green,motion],name='attention')\n",
    "output_all = concatenate([output_best,output_red,output_ir,output_green],name='output')\n",
    "encoded = Bidirectional(GRU(timesteps,return_sequences=True,activation='relu',go_backwards=True))(output_all)\n",
    "\n",
    "att = Dense(1,activation='relu')(at_all)\n",
    "att = Flatten()(att)\n",
    "att = Activation(activation=\"softmax\")(att)\n",
    "att = RepeatVector(timesteps*2)(att)\n",
    "att = Permute((2,1))(att)\n",
    "mer = multiply([att, encoded])\n",
    "mer = Dense(10,activation='relu')(mer)\n",
    "mer = Flatten()(mer)\n",
    "mer = Dense(30,activation='relu',name='sequence1')(mer)\n",
    "mer = Dense(60,activation='relu',name='sequence')(mer)\n",
    "sequence_autoencoder = Model(inputs=[inputs], outputs=[mer])\n",
    "sequence_autoencoder.compile(optimizer='adam',loss='logcosh',metrics=['mae'])\n",
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32330 samples, validate on 8083 samples\n",
      "Epoch 1/300\n",
      "32330/32330 [==============================] - 23s 722us/step - loss: 444.3296 - mae: 445.0220 - val_loss: 315.6391 - val_mae: 316.3308\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 315.63912, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 2/300\n",
      "32330/32330 [==============================] - 23s 727us/step - loss: 317.8268 - mae: 318.5185 - val_loss: 312.8597 - val_mae: 313.5514\n",
      "\n",
      "Epoch 00002: val_loss improved from 315.63912 to 312.85969, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 3/300\n",
      "32330/32330 [==============================] - 24s 743us/step - loss: 314.0576 - mae: 314.7493 - val_loss: 311.0632 - val_mae: 311.7547\n",
      "\n",
      "Epoch 00003: val_loss improved from 312.85969 to 311.06317, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 4/300\n",
      "32330/32330 [==============================] - 23s 723us/step - loss: 310.2839 - mae: 310.9755 - val_loss: 307.7054 - val_mae: 308.3970\n",
      "\n",
      "Epoch 00004: val_loss improved from 311.06317 to 307.70540, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 5/300\n",
      "32330/32330 [==============================] - 23s 718us/step - loss: 308.7630 - mae: 309.4545 - val_loss: 306.6427 - val_mae: 307.3341\n",
      "\n",
      "Epoch 00005: val_loss improved from 307.70540 to 306.64274, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 6/300\n",
      "32330/32330 [==============================] - 23s 720us/step - loss: 306.6211 - mae: 307.3124 - val_loss: 305.6538 - val_mae: 306.3451\n",
      "\n",
      "Epoch 00006: val_loss improved from 306.64274 to 305.65379, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 7/300\n",
      "32330/32330 [==============================] - 23s 726us/step - loss: 306.5588 - mae: 307.2502 - val_loss: 306.2834 - val_mae: 306.9747\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 305.65379\n",
      "Epoch 8/300\n",
      "32330/32330 [==============================] - 23s 725us/step - loss: 306.1908 - mae: 306.8821 - val_loss: 303.7460 - val_mae: 304.4374\n",
      "\n",
      "Epoch 00008: val_loss improved from 305.65379 to 303.74605, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 9/300\n",
      "32330/32330 [==============================] - 30s 941us/step - loss: 306.8349 - mae: 307.5262 - val_loss: 304.1697 - val_mae: 304.8611\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 303.74605\n",
      "Epoch 10/300\n",
      "32330/32330 [==============================] - 31s 945us/step - loss: 305.6293 - mae: 306.3206 - val_loss: 307.1870 - val_mae: 307.8784\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 303.74605\n",
      "Epoch 11/300\n",
      "32330/32330 [==============================] - 31s 946us/step - loss: 310.6386 - mae: 311.3300 - val_loss: 312.2703 - val_mae: 312.9617\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 303.74605\n",
      "Epoch 12/300\n",
      "32330/32330 [==============================] - 23s 720us/step - loss: 307.6113 - mae: 308.3026 - val_loss: 304.4651 - val_mae: 305.1564\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 303.74605\n",
      "Epoch 13/300\n",
      "32330/32330 [==============================] - 23s 721us/step - loss: 304.2207 - mae: 304.9118 - val_loss: 303.4453 - val_mae: 304.1363\n",
      "\n",
      "Epoch 00013: val_loss improved from 303.74605 to 303.44528, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 14/300\n",
      "32330/32330 [==============================] - 24s 735us/step - loss: 303.1164 - mae: 303.8074 - val_loss: 301.1821 - val_mae: 301.8731\n",
      "\n",
      "Epoch 00014: val_loss improved from 303.44528 to 301.18212, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 15/300\n",
      "32330/32330 [==============================] - 24s 733us/step - loss: 301.3052 - mae: 301.9962 - val_loss: 301.1832 - val_mae: 301.8741\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 301.18212\n",
      "Epoch 16/300\n",
      "32330/32330 [==============================] - 24s 743us/step - loss: 300.9292 - mae: 301.6201 - val_loss: 298.3503 - val_mae: 299.0409\n",
      "\n",
      "Epoch 00016: val_loss improved from 301.18212 to 298.35027, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 17/300\n",
      "32330/32330 [==============================] - 24s 743us/step - loss: 299.5026 - mae: 300.1934 - val_loss: 297.9601 - val_mae: 298.6507\n",
      "\n",
      "Epoch 00017: val_loss improved from 298.35027 to 297.96008, saving model to ../models/base_LSTM_attention_divided.hdf5\n",
      "Epoch 18/300\n",
      "32330/32330 [==============================] - 24s 740us/step - loss: 300.7897 - mae: 301.4807 - val_loss: 297.9689 - val_mae: 298.6596\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 297.96008\n",
      "Epoch 19/300\n",
      "32330/32330 [==============================] - 26s 818us/step - loss: 299.1389 - mae: 299.8296 - val_loss: 298.1752 - val_mae: 298.8660\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 297.96008\n",
      "Epoch 20/300\n",
      "32330/32330 [==============================] - 28s 868us/step - loss: 299.4496 - mae: 300.1404 - val_loss: 298.1555 - val_mae: 298.8464\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 297.96008\n",
      "Epoch 21/300\n",
      "19500/32330 [=================>............] - ETA: 10s - loss: 300.0524 - mae: 300.7432"
     ]
    }
   ],
   "source": [
    "filepath = '../models/base_LSTM_attention_divided.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=20)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = sequence_autoencoder.fit(X_train, y_train,\n",
    "                epochs=300,\n",
    "                batch_size=500,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val,y_val),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow_probability as tfp\n",
    "filepath = '../models/base_LSTM_attention_divided.hdf5'\n",
    "sequence_autoencoder = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = sequence_autoencoder.predict(X_test)\n",
    "y_pred = y_pred1[0]\n",
    "mean_pred = y_pred1[1]\n",
    "stds_pred = y_pred1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1[0].shape,y_pred1[1].shape,y_pred1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(y[-10])\n",
    "for i,a in enumerate(y_pred[::-1][200:210]):\n",
    "#     if np.sum(a)>0:\n",
    "    plt.figure()\n",
    "    plt.plot(a,'g')\n",
    "#         plt.plot(X[i,:,:],'r')\n",
    "    plt.plot(y_test[i],'b')\n",
    "    plt.plot(ecg_test[i],'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(quals_test.reshape(-1)),4))\n",
    "X[:,0] = quals_test.reshape(-1)\n",
    "X[:,1] = y_pred.reshape(-1)\n",
    "X[:,2] = ecg_test.reshape(-1)\n",
    "X[:,3] = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X[:,0]>-1]\n",
    "X = X[X[:,2]>0]\n",
    "X = X[X[:,3]>0]\n",
    "# X = X[X[:,1]>0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_range = np.arange(0,1,.05)\n",
    "x = []\n",
    "y = []\n",
    "y1 = []\n",
    "for l in l_range:\n",
    "    index = np.where((X[:,0]>=l)&(X[:,0]<l+.05))[0]\n",
    "    temp = X[index]\n",
    "    print(temp.shape,l)\n",
    "    x.append(str(np.round(l*100)/100)+'-'+str(np.round((l+.05)*100)/100))\n",
    "    y.append(list(np.abs(temp[:,2]-temp[:,3])))\n",
    "    a = np.array(np.abs(temp[:,1]-temp[:,2]))\n",
    "    y1.append(a[~np.isnan(a)])\n",
    "print(len(y),len(y1))\n",
    "#     print(np.mean(np.abs(temp[:,0]-temp[:,2])),np.std(np.abs(temp[:,0]-temp[:,2])),len(index))\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size':20})\n",
    "c = plt.boxplot(y,showfliers=False,positions=np.array(range(0,3*len(y),3)),notch=True)\n",
    "for box in c['boxes']:\n",
    "    box.set(color='red', linewidth=1)\n",
    "b = plt.boxplot(y1,showfliers=False,positions=np.array(range(0,3*len(y),3))+1.5,notch=True)\n",
    "for box in b['boxes']:\n",
    "    box.set(color='blue', linewidth=1)\n",
    "#     box.set(facecolor = 'red' )\n",
    "plt.xticks(np.array(range(0,3*len(y),3)),x,rotation=60)\n",
    "plt.ylabel('Absolute Difference in Milliseconds')\n",
    "plt.xlabel('Range of Signal Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrvanalysis import get_time_domain_features\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "q = []\n",
    "s = 'range_nni'\n",
    "for i in range(ecg_test.shape[0]):\n",
    "    qual_min = quals_test[i].reshape(-1)\n",
    "    qual_min = qual_min[qual_min>-1]\n",
    "    ecg_min = ecg_test[i].reshape(-1)\n",
    "    ecg_min = ecg_min[ecg_min>0]\n",
    "    ecg_min= ecg_min[~np.isnan(ecg_min)]\n",
    "    y_pred_min = y_pred[i].reshape(-1)\n",
    "    y_pred_min = y_pred_min[~np.isnan(y_pred_min)]\n",
    "    y_test_min = y_test[i].reshape(-1)\n",
    "    y_test_min = y_test_min[y_test_min>0]\n",
    "    y_test_min = y_test_min[~np.isnan(y_test_min)]\n",
    "    if len(ecg_min)<10 or len(y_pred_min)<5 or len(y_test_min)<5:\n",
    "        continue\n",
    "    x.append(np.array(list(get_time_domain_features(y_pred_min).values())))\n",
    "    y.append(np.array(list(get_time_domain_features(ecg_min).values())))\n",
    "    z.append(np.array(list(get_time_domain_features(y_test_min).values())))\n",
    "    q.append(np.median(qual_min))\n",
    "#     if np.isinf(x[-1]) or np.isinf(y[-1]) or np.isinf(z[-1]) or np.isinf(q[-1]):\n",
    "#         x = x[:-1]\n",
    "#         y= y[:-1]\n",
    "#         z= z[:-1]\n",
    "#         q= q[:-1]\n",
    "#     elif np.isnan(x[-1]) or np.isnan(y[-1]) or np.isnan(z[-1]) or np.isnan(q[-1]):\n",
    "#         x = x[:-1]\n",
    "#         y= y[:-1]\n",
    "#         z= z[:-1]\n",
    "#         q= q[:-1]\n",
    "#     print(np.std(ecg_min),np.std(y_test_min),np.std(y_pred_min),np.median(qual_min))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z,q = np.array(x),np.array(y),np.array(z),np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['mean_nni', 'sdnn', 'sdsd', 'nni_50', 'pnni_50', 'nni_20', 'pnni_20', 'rmssd',\n",
    " 'median_nni', 'range_nni', 'cvsd', 'cvnni', 'mean_hr', 'max_hr', 'min_hr', 'std_hr']\n",
    "quality_col = ['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(feature_col):\n",
    "    ecg_i = y[:,i]\n",
    "    x_i = x[:,i]\n",
    "    diffs = np.abs(ecg_i-x_i)\n",
    "    plt.figure()\n",
    "    plt.plot(q,diffs)\n",
    "    plt.show()\n",
    "    print(mean_absolute_error(ecg_i,x_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "%matplotlib inline\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "def aic(X,y):\n",
    "    regr = OLS(y, add_constant(X)).fit()\n",
    "    return regr.aic\n",
    "\n",
    "# from sklearn.utils import check_arrays\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "#     y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    #if _is_1d(y_true): \n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+1))) * 100\n",
    "\n",
    "def output(quality,features_ecg,features1,j,q_name):\n",
    "    \n",
    "    for i,f_name in enumerate(feature_col):\n",
    "        features = features1[:,i]\n",
    "        ground_truth = features_ecg[:,i]\n",
    "        qual = quality[:,j]\n",
    "#         output(quals,input_ecg,input_ppg,f_name,q_name)\n",
    "    \n",
    "        l_range = np.arange(0,1,.1)\n",
    "        x = []\n",
    "        y = []\n",
    "        for l in l_range:\n",
    "            index = np.where((qual>=l)&(qual<l+.1))[0]\n",
    "            if len(index)<2:\n",
    "                continue\n",
    "            temp_input = features[index]\n",
    "            temp_output = ground_truth[index]\n",
    "            x.append(l)\n",
    "    #         y.append(aic(temp_input,temp_output))\n",
    "            y.append(pearsonr(temp_output,temp_input)[0])\n",
    "    #     plt.boxplot(y,showfliers=False)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.rcParams.update({'font.size':20})\n",
    "        plt.bar(x,y,.05,label = str(f_name))\n",
    "#         plt.plot(x,y,label = str(f_name) )\n",
    "    #     plt.xticks(range(1,len(x)+1),x,rotation=60)\n",
    "        plt.ylabel('Percentage Error')\n",
    "        plt.xlabel('Range of Signal Quality-'+str(q_name))\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,q_name in enumerate(quality_col):\n",
    "    output(q,x,y,j,q_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,spearmanr\n",
    "q,x,y,z = np.array(q),np.array(x),np.array(y),np.array(z)\n",
    "for i in np.linspace(0,.9,10):\n",
    "    index = np.where((q>=i)&(q<=i+.1))[0]\n",
    "    if len(index)<2:\n",
    "        continue\n",
    "    print(pearsonr(x[index],y[index]),pearsonr(y[index],z[index]),i,i+.1,len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(y.reshape(-1),50)\n",
    "plt.hist(y_pred.reshape(-1),50)\n",
    "plt.hist(ecg_test.reshape(-1),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y[0].reshape(1,-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred1[1].reshape(-1),means_test.reshape(-1),'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(y_pred1[1].reshape(-1),means_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[np.isfinite(t)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(quals_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
