{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# data = pickle.load(open('../data/leftppgecg.p','rb'))\n",
    "directory = '../data_users/ecg_ppg/'\n",
    "dfs = []\n",
    "for f in os.listdir(directory)[:50]:\n",
    "    if f[-1]!='p':\n",
    "        continue\n",
    "    a = pickle.load(open(directory+f,'rb'))\n",
    "    print(a.shape,end=',')\n",
    "    dfs.append(a)\n",
    "print()\n",
    "data1 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "data_all = deepcopy(data1)\n",
    "\n",
    "data_all['red_rr'] = data_all['ppg_rr'].apply(lambda x:x[0])\n",
    "data_all['ir_rr'] = data_all['ppg_rr'].apply(lambda x:x[1])\n",
    "data_all['green_rr'] = data_all['ppg_rr'].apply(lambda x:x[2])\n",
    "data_all['red_qual'] = data_all['likelihood'].apply(lambda x:x[0])\n",
    "data_all['ir_qual'] = data_all['likelihood'].apply(lambda x:x[1])\n",
    "data_all['green_qual'] = data_all['likelihood'].apply(lambda x:x[2])\n",
    "data_all['index'] = data_all['likelihood'].apply(lambda x:np.argmax(np.array(x)))\n",
    "values = data_all[['ppg_rr','index']].values\n",
    "values = [a[b] for a,b in values]\n",
    "data_all['ppg_rr_best'] = values\n",
    "data_all['likelihood_best'] = data_all['likelihood'].apply(lambda x:max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_all,open('../data_users/merged_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "data_all = pickle.load(open('../data_users/merged_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=20)]: Done 241 out of 241 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 182 out of 182 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44514a20-82cf-45ee-8fae-828f2ec4f035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=20)]: Done 19305 out of 19305 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  23 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done  23 out of  23 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3133920d-164a-48e6-8d9e-79e919c45d43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 11645 out of 11645 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1104 out of 1104 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72cc0041-a4a9-4194-b1e3-bf8e829c5eee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 3224 out of 3224 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c5e2565c-3956-43f4-9b83-4e9a0bd1a0d0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 24600 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=20)]: Done 31400 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=20)]: Done 39000 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=20)]: Done 40766 out of 40766 | elapsed:   38.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 2256 out of 2295 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 2295 out of 2295 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1b4671b-623b-42b9-a216-42d57ba8cc61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  78 out of  78 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d058f876-d943-4cb0-8e07-540dabb1d7f6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=20)]: Done 7800 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=20)]: Done 7932 out of 7932 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 1459 out of 1459 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "099b45df-6432-47d2-8332-a8a870ec79de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 20658 out of 20658 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  11 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  74 out of 113 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 113 out of 113 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f2bdd151-3fb8-497a-8380-a2b65dc01c2c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4150 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=20)]: Done 4433 out of 4433 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 202 out of 202 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1895fe4-14ca-4433-95c1-3430fc4c8c35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 12499 out of 12499 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e79e7e79-93ea-49bf-85ce-c174492c8a14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done 2892 out of 2892 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of   6 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   6 out of   6 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2c68bc6e-7756-4e00-9a7b-face9ba98cec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=20)]: Done 20073 out of 20073 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  11 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 616 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 1860 out of 1860 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b71b2071-6330-434d-a2ab-8e929e9b96a9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 6905 out of 6905 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 924 out of 924 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37ab3c6b-092a-494d-a9b8-9f961e9d008a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 1049 out of 1049 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eccf2bea-169d-4dce-a9b9-93b4e0c7be83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 11000 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=20)]: Done 19800 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=20)]: Done 21883 out of 21883 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 647 out of 647 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0dbd4034-a57f-4056-a8a1-e0d6ba8fdd93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=20)]: Done 6012 out of 6051 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 6051 out of 6051 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done  61 out of  61 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59ae4c3e-e2d1-4cba-b314-92656fe65360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 440 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 2440 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 2807 out of 2807 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a8c3335f-fd55-40d0-b6e8-08423e67ad22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=20)]: Done 10200 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=20)]: Done 17400 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=20)]: Done 21844 out of 21844 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1660 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=20)]: Done 1826 out of 1826 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8008f00d-2549-46e4-ab1f-01542c1076e2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 20122 out of 20161 | elapsed:   19.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 20161 out of 20161 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 1059 out of 1059 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ddc3405-d256-4f66-95df-2b13bf69a616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 608 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=20)]: Done 7084 out of 7084 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8d3b24b0-a89e-4ff2-aee2-8f7f67e2798c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2250 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=20)]: Done 2313 out of 2313 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 320 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 417 out of 417 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460a483c-21fc-4ef6-a44a-740d43b81ed4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 608 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=20)]: Done 10200 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=20)]: Done 14084 out of 14084 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 744 out of 744 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0f051e0-69ef-4153-9a1e-22ed921d76c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=20)]: Done 16744 out of 16744 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 276 out of 315 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 315 out of 315 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b4bce96-dccb-434b-b4ca-63c7fcd3a7fa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 1343 out of 1343 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc40ffe4-1ec1-4add-bd8b-beb10e727783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=20)]: Done 20098 out of 20098 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 6690 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=20)]: Done 6991 out of 6991 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8d96c9a4-a13b-4729-adf3-969e84b9a6d2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 440 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 1114 out of 1114 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 142 out of 142 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bba69ab9-3b12-45c1-997e-f64909174649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=20)]: Done 20699 out of 20699 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522a66a7-1502-46fe-bce4-9e022c52219f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=20)]: Done 13891 out of 13891 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done 400 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 2205 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=20)]: Done 2404 out of 2404 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98fca87c-9940-4666-9893-9f8ae2418cb8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=20)]: Done 19332 out of 19332 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 4550 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=20)]: Done 4938 out of 4938 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87877961-b2f8-4256-806b-973fbd798920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=20)]: Done 19908 out of 19908 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 5340 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done 5510 out of 5510 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bde40f50-8e35-4707-8260-b69f07773c4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=20)]: Done 10200 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=20)]: Done 17400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 19679 out of 19679 | elapsed:   14.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81d3b376-3549-4639-aad5-35670e772492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=20)]: Done 20515 out of 20515 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 1450 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=20)]: Done 1639 out of 1639 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f3f7553-6d2f-4c08-adb9-dbc3e88ba0aa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 19312 out of 19312 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 933 out of 933 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00c08d2f-3b9c-48e9-9633-5a341892cc4b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=20)]: Done 9300 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=20)]: Done 9347 out of 9347 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1888 out of 1888 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba115c26-1c87-418c-9f6b-2816cd6673ca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=20)]: Done 16264 out of 16264 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  11 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 616 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 4551 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=20)]: Done 4754 out of 4754 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7846909f-c4a5-4d49-b11d-d1b1ca2c7309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=20)]: Done 19600 out of 19600 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 1660 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=20)]: Done 1812 out of 1812 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3cf5812-85fd-4328-9b2a-1b3b6b2cd0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=20)]: Done 21232 out of 21232 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 3200 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=20)]: Done 3448 out of 3487 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 3487 out of 3487 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d8b5a8c-e990-4442-abf6-578e96d2f5eb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 15777 out of 15777 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1660 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=20)]: Done 1762 out of 1801 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 1801 out of 1801 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263b1782-923d-4bb3-b52d-4c1926e81f1f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  11 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 608 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2608 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5408 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9008 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13408 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18608 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 19199 out of 19199 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 2690 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=20)]: Done 2799 out of 2799 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34e42cf6-7c34-417c-a003-874e3b6151e7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 4082 out of 4082 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 166 out of 166 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7ab70ff6-9e38-4e6f-8704-b5b4c5da730e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 102 out of 141 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 141 out of 141 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23584088-0cf3-42ec-8088-dac7d51ab037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=20)]: Done 19948 out of 19948 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 746 out of 746 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd7235b7-56ac-49a9-a0a7-b309e0f3507c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 440 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 1309 out of 1309 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d8278ae-4620-4106-9061-0d00625bb85d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 4600 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=20)]: Done 10200 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=20)]: Done 15741 out of 15741 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1392 out of 1392 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780e89b3-f6bf-4181-9f2c-7db941735c87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=20)]: Done 20240 out of 20240 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b63e06f-4931-41e2-aa62-1eb51c5e250b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=20)]: Done 20120 out of 20120 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 1450 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=20)]: Done 1627 out of 1627 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e099e913-4796-4408-af63-1d35c84f29fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 440 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 3880 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=20)]: Done 9480 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=20)]: Done 10053 out of 10053 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 1923 out of 1923 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903c1dae-a771-405f-a021-6f175724adc4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=20)]: Done 20319 out of 20319 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 4250 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done 4548 out of 4548 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892e71e0-a5a4-4315-89a4-fa5518d78591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=20)]: Done 19480 out of 19480 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 6690 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=20)]: Done 7032 out of 7071 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 7071 out of 7071 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fdddb3bd-bb88-458f-bcc8-e50bb3f87742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done 2600 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 5400 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=20)]: Done 9000 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=20)]: Done 13400 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=20)]: Done 18600 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=20)]: Done 23117 out of 23117 | elapsed:   22.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 3310 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02543bbf-84c2-4076-8547-c8a5f451ea02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 3519 out of 3519 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "def get_data1(a):\n",
    "    features = []\n",
    "    ecg_rr = a[:,-1]\n",
    "    if len(ecg_rr[np.isnan(ecg_rr)])>0:\n",
    "        return [],[],[],[],[],[]\n",
    "    m = np.mean(ecg_rr[ecg_rr>0])\n",
    "    s = np.std(ecg_rr[ecg_rr>0])\n",
    "    ecg_rr[np.isnan(ecg_rr)] = 0\n",
    "    if len(ecg_rr)<60:\n",
    "        return [],[],[],[],[],[]\n",
    "    y = []\n",
    "    X = []\n",
    "    ecg = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    quals = []\n",
    "    for i in [-2]:\n",
    "        ppg_rr = a[:,i]\n",
    "        ppg_qual = a[:,i-4]\n",
    "#         index = ppg_rr>0\n",
    "#         ppg_qual = ppg_qual[index]\n",
    "#         ppg_rr = ppg_rr[index]\n",
    "        index = np.isnan(ppg_rr)\n",
    "        index1 = ~np.isnan(ppg_rr)\n",
    "        if len(ppg_rr[index1])<60:\n",
    "            continue\n",
    "        ppg_qual[index] = -1\n",
    "        ppg_rr[index] = np.nanmean(ppg_rr)\n",
    "        y.append(ecg_rr.reshape(1,60,1))\n",
    "        tmp = a[:,np.array([-2,-3,-4,-5,-6,-7,-8,-9,1])].reshape(1,60,9)\n",
    "        tmp[np.isnan(tmp)] = 0\n",
    "        tmp[tmp==0] = 0\n",
    "        X.append(tmp)\n",
    "        means.append(m)\n",
    "        stds.append(s)\n",
    "        ecg.append(ppg_rr.reshape(1,60,1))\n",
    "        quals.append(ppg_qual.reshape(1,60,1))\n",
    "#         for j in np.linspace(0,.9,20):\n",
    "#             index = ppg_qual>j\n",
    "#             ppg_qual = ppg_qual[index]\n",
    "#             ppg_rr = ppg_rr[index]\n",
    "#             if len(ppg_rr)<10:\n",
    "#                 continue\n",
    "#             f = list(get_time_domain_features(ppg_rr).values())\n",
    "#             f1 = list(get_time_domain_features(ecg_rr).values())\n",
    "#             q = [np.percentile(ppg_qual,20),np.median(ppg_qual),len(ppg_rr)/60]\n",
    "#             features.append(np.array(f1+f+q))\n",
    "    return X,y,ecg,means,stds,quals\n",
    "\n",
    "unique_users = data_all['user'].unique()\n",
    "\n",
    "def get_data(name,df):\n",
    "    df = df[['time','activity','red_qual','ir_qual','green_qual','likelihood_best',\n",
    "             'red_rr','ir_rr','green_rr','ppg_rr_best','ecg_rr']].values\n",
    "    return df.reshape(-1,60,11)\n",
    "all_X = []\n",
    "for user in unique_users:\n",
    "    data_user = data_all[data_all.user.isin([user])]\n",
    "    data_user.set_index('timestamp',inplace=True)\n",
    "    convert_dict = {'ecg_rr': float}\n",
    "    data_user = data_user.astype(convert_dict) \n",
    "    data_resampled = data_user.resample('1S').mean()\n",
    "    if 'ecg_rr' not in np.array(data_resampled.columns.values):\n",
    "        continue\n",
    "    df_col = Parallel(n_jobs=20,verbose=1)(delayed(get_data)(group_name, df_group) for group_name, df_group\n",
    "                                           in data_resampled.groupby(pd.Grouper(freq='60S')) if df_group.shape[0]==60)\n",
    "#     df_col = [get_data(group_name, df_group) for group_name, df_group\n",
    "#                                            in data_resampled.groupby(pd.Grouper(freq='60S')) if df_group.shape[0]==60]\n",
    "    df_user = np.concatenate(df_col)\n",
    "    df_col = Parallel(n_jobs=20,verbose=1)(delayed(get_data1)(a) for a in df_user if len(a[~np.isnan(a[:,-1]),-1])>20)    \n",
    "    all_X.extend(df_col)\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = [],[],[],[],[],[]\n",
    "for a in all_X:\n",
    "    if len(a[0])==0:\n",
    "        continue\n",
    "    X.extend(a[0])\n",
    "    y.extend(a[1])\n",
    "    ecg.extend(a[2])\n",
    "    means.extend(a[3])\n",
    "    stds.extend(a[4])\n",
    "    quals.extend(a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([X,y,ecg,means,stds,quals],open('../data_users/processed_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "X,y,ecg,means,stds,quals = pickle.load(open('../data_users/processed_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = np.concatenate(X),np.concatenate(y).reshape(-1,60),np.concatenate(ecg).reshape(-1,60),\\\n",
    "np.array(means).reshape(-1,1),np.array(stds).reshape(-1,1),np.concatenate(quals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6786, 60, 5) (6786, 60) (1697, 60) (1697, 1) (1697, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector,Bidirectional,Multiply,multiply,Permute\n",
    "from keras.layers import TimeDistributed,Dense,Flatten,Reshape,Lambda,Activation,GRU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras import metrics,losses\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "X_train, X_test, y_train, y_test,ecg_train, \\\n",
    "ecg_test,means_train,means_test,stds_train,stds_test, \\\n",
    "quals_train,quals_test= train_test_split(\n",
    "    X[:,:,np.array([0,1,2,3,4])], y,ecg,means,stds,quals, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val,means_train,means_val,stds_train,stds_val = train_test_split(\n",
    "    X_train, y_train,means_train,stds_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape,y_val.shape,means_val.shape,stds_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 60, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 60, 120)      23760       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 60, 1)        121         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 60)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 60)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 120, 60)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 60, 120)      0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 60, 120)      0           permute_1[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 60, 1)        121         multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 60)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sequence (Dense)                (None, 60)           3660        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mean (Lambda)                   (None, 1)            0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "std (Lambda)                    (None, 1)            0           sequence[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 27,662\n",
      "Trainable params: 27,662\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def output_of_lambda(input_shape):\n",
    "    return (input_shape[0], 1)\n",
    "\n",
    "def mean(x):\n",
    "    return K.mean(x, axis=1, keepdims=True)\n",
    "\n",
    "def output_of_lambda1(input_shape):\n",
    "    return (input_shape[0], 1)\n",
    "\n",
    "def mean1(x):\n",
    "    return K.std(x, axis=1, keepdims=True)\n",
    "\n",
    "timesteps = 60\n",
    "input_dim = 5\n",
    "latent_dim = 20\n",
    "output_dim = 1\n",
    "n = 1\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "# inputs2 = Reshape((1,1))(inputs1)\n",
    "encoded = Bidirectional(GRU(60,return_sequences=True,activation='relu',go_backwards=True))(inputs)\n",
    "# encoded = LSTM(output_dim,return_sequences=True,activation='sigmoid')(encoded)\n",
    "att = Dense(1,activation='relu')(encoded)\n",
    "\n",
    "att = Flatten()(att)\n",
    "att = Activation(activation=\"softmax\")(att)\n",
    "att = RepeatVector(120)(att)\n",
    "att = Permute((2,1))(att)\n",
    "mer = multiply([att, encoded])\n",
    "\n",
    "encoded = TimeDistributed(Dense(1,activation='relu'))(mer)\n",
    "encoded = Flatten()(encoded)\n",
    "# encoded = Dense(10,activation='relu',name='sequence1')(encoded)\n",
    "encoded = Dense(60,activation='relu',name='sequence')(encoded)\n",
    "# encoded = Reshape((60),name='sequence')(encoded)\n",
    "# encoded_std = K.std(encoded,axis=1)\n",
    "decoded = Lambda(mean, output_shape=output_of_lambda,name='mean')(encoded)\n",
    "decoded1 = Lambda(mean1, output_shape=output_of_lambda1,name='std')(encoded)\n",
    "# decoded = LSTM(output_dim*60, return_sequences=True)(decoded)\n",
    "# decoded = LSTM(output_dim*3, return_sequences=True)(decoded)\n",
    "# decoded = LSTM(output_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs=[inputs], outputs=[encoded,decoded,decoded1])\n",
    "# encoder = Model(inputs, encoded)\n",
    "losses = {\n",
    "    \"std\":\"mae\",\n",
    "    \"mean\": \"mae\",\n",
    "    \"sequence\": \"mae\"\n",
    "}\n",
    "lossWeights = {\"mean\": 0, \"sequence\": 1,\"std\":0}\n",
    "# initialize the optimizer and compile the model\n",
    "\n",
    "sequence_autoencoder.compile(optimizer='adam',loss=losses, loss_weights=lossWeights)\n",
    "\n",
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6786 samples, validate on 1697 samples\n",
      "Epoch 1/300\n",
      "6786/6786 [==============================] - 7s 1ms/step - loss: 634.9004 - sequence_loss: 634.7698 - mean_loss: 634.7698 - std_loss: 36.2917 - val_loss: 568.8140 - val_sequence_loss: 568.8242 - val_mean_loss: 568.8242 - val_std_loss: 94.8834\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 568.81398, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 2/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 459.2380 - sequence_loss: 459.0777 - mean_loss: 447.2945 - std_loss: 186.6703 - val_loss: 386.2578 - val_sequence_loss: 386.2764 - val_mean_loss: 354.4275 - val_std_loss: 242.8112\n",
      "\n",
      "Epoch 00002: val_loss improved from 568.81398 to 386.25778, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 3/300\n",
      "6786/6786 [==============================] - 6s 884us/step - loss: 336.2216 - sequence_loss: 336.1483 - mean_loss: 291.6076 - std_loss: 248.8277 - val_loss: 300.5981 - val_sequence_loss: 300.6118 - val_mean_loss: 244.4496 - val_std_loss: 246.6955\n",
      "\n",
      "Epoch 00003: val_loss improved from 386.25778 to 300.59810, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 4/300\n",
      "6786/6786 [==============================] - 6s 889us/step - loss: 261.9179 - sequence_loss: 261.8773 - mean_loss: 201.9183 - std_loss: 232.3316 - val_loss: 232.6234 - val_sequence_loss: 232.6241 - val_mean_loss: 170.4012 - val_std_loss: 215.0416\n",
      "\n",
      "Epoch 00004: val_loss improved from 300.59810 to 232.62343, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 5/300\n",
      "6786/6786 [==============================] - 6s 876us/step - loss: 198.0621 - sequence_loss: 198.0121 - mean_loss: 142.5591 - std_loss: 183.9012 - val_loss: 175.8419 - val_sequence_loss: 175.8478 - val_mean_loss: 133.1215 - val_std_loss: 146.2850\n",
      "\n",
      "Epoch 00005: val_loss improved from 232.62343 to 175.84189, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 6/300\n",
      "6786/6786 [==============================] - 6s 833us/step - loss: 146.3598 - sequence_loss: 146.3278 - mean_loss: 111.2658 - std_loss: 104.4430 - val_loss: 128.4164 - val_sequence_loss: 128.4198 - val_mean_loss: 106.5721 - val_std_loss: 58.6348\n",
      "\n",
      "Epoch 00006: val_loss improved from 175.84189 to 128.41644, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 7/300\n",
      "6786/6786 [==============================] - 6s 817us/step - loss: 113.3133 - sequence_loss: 113.3086 - mean_loss: 100.4104 - std_loss: 37.7831 - val_loss: 110.9112 - val_sequence_loss: 110.9179 - val_mean_loss: 104.2162 - val_std_loss: 26.1219\n",
      "\n",
      "Epoch 00007: val_loss improved from 128.41644 to 110.91118, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 8/300\n",
      "6786/6786 [==============================] - 6s 828us/step - loss: 102.4027 - sequence_loss: 102.3704 - mean_loss: 96.5835 - std_loss: 26.2839 - val_loss: 105.8894 - val_sequence_loss: 105.8961 - val_mean_loss: 101.3181 - val_std_loss: 26.6677\n",
      "\n",
      "Epoch 00008: val_loss improved from 110.91118 to 105.88942, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 9/300\n",
      "6786/6786 [==============================] - 6s 837us/step - loss: 98.6914 - sequence_loss: 98.6810 - mean_loss: 93.9910 - std_loss: 26.4627 - val_loss: 102.5834 - val_sequence_loss: 102.5904 - val_mean_loss: 98.5025 - val_std_loss: 26.0948\n",
      "\n",
      "Epoch 00009: val_loss improved from 105.88942 to 102.58337, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 10/300\n",
      "6786/6786 [==============================] - 5s 801us/step - loss: 96.9278 - sequence_loss: 96.9432 - mean_loss: 92.3455 - std_loss: 26.3148 - val_loss: 101.7495 - val_sequence_loss: 101.7574 - val_mean_loss: 97.6868 - val_std_loss: 26.5173\n",
      "\n",
      "Epoch 00010: val_loss improved from 102.58337 to 101.74955, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 11/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 95.8671 - sequence_loss: 95.8565 - mean_loss: 91.1982 - std_loss: 26.5687 - val_loss: 100.1706 - val_sequence_loss: 100.1704 - val_mean_loss: 96.0283 - val_std_loss: 26.1454\n",
      "\n",
      "Epoch 00011: val_loss improved from 101.74955 to 100.17058, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 12/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 95.8034 - sequence_loss: 95.8082 - mean_loss: 91.2301 - std_loss: 26.2729 - val_loss: 100.7699 - val_sequence_loss: 100.7724 - val_mean_loss: 96.8514 - val_std_loss: 26.2889\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 100.17058\n",
      "Epoch 13/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 95.8650 - sequence_loss: 95.8816 - mean_loss: 91.4182 - std_loss: 26.2229 - val_loss: 100.5876 - val_sequence_loss: 100.5917 - val_mean_loss: 96.6416 - val_std_loss: 26.2668\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 100.17058\n",
      "Epoch 14/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 94.9748 - sequence_loss: 94.9873 - mean_loss: 90.4264 - std_loss: 26.2107 - val_loss: 98.1224 - val_sequence_loss: 98.1249 - val_mean_loss: 93.8684 - val_std_loss: 26.1520\n",
      "\n",
      "Epoch 00014: val_loss improved from 100.17058 to 98.12241, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 15/300\n",
      "6786/6786 [==============================] - 6s 911us/step - loss: 92.9744 - sequence_loss: 92.9672 - mean_loss: 88.2341 - std_loss: 26.2916 - val_loss: 94.2199 - val_sequence_loss: 94.2363 - val_mean_loss: 89.9612 - val_std_loss: 26.4842\n",
      "\n",
      "Epoch 00015: val_loss improved from 98.12241 to 94.21990, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 16/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 91.0483 - sequence_loss: 91.0308 - mean_loss: 86.2253 - std_loss: 26.4834 - val_loss: 93.3394 - val_sequence_loss: 93.3346 - val_mean_loss: 88.7655 - val_std_loss: 26.3584\n",
      "\n",
      "Epoch 00016: val_loss improved from 94.21990 to 93.33935, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 17/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 89.7823 - sequence_loss: 89.7691 - mean_loss: 84.9067 - std_loss: 26.5537 - val_loss: 94.1495 - val_sequence_loss: 94.1479 - val_mean_loss: 90.0454 - val_std_loss: 26.7199\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 93.33935\n",
      "Epoch 18/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 90.2798 - sequence_loss: 90.2827 - mean_loss: 85.4934 - std_loss: 26.5709 - val_loss: 92.3917 - val_sequence_loss: 92.3954 - val_mean_loss: 87.9540 - val_std_loss: 26.5090\n",
      "\n",
      "Epoch 00018: val_loss improved from 93.33935 to 92.39170, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 19/300\n",
      "6786/6786 [==============================] - 6s 909us/step - loss: 90.2456 - sequence_loss: 90.2430 - mean_loss: 85.3814 - std_loss: 26.4979 - val_loss: 95.9164 - val_sequence_loss: 95.9144 - val_mean_loss: 91.4951 - val_std_loss: 26.6490\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 92.39170\n",
      "Epoch 20/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 95.3700 - sequence_loss: 95.3767 - mean_loss: 90.8827 - std_loss: 26.6861 - val_loss: 100.7637 - val_sequence_loss: 100.7696 - val_mean_loss: 96.5126 - val_std_loss: 26.7018\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 92.39170\n",
      "Epoch 21/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 93.0024 - sequence_loss: 92.9885 - mean_loss: 88.3180 - std_loss: 26.6255 - val_loss: 93.7501 - val_sequence_loss: 93.7448 - val_mean_loss: 89.0946 - val_std_loss: 26.6470\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 92.39170\n",
      "Epoch 22/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 90.6578 - sequence_loss: 90.6689 - mean_loss: 85.9309 - std_loss: 26.5224 - val_loss: 93.7421 - val_sequence_loss: 93.7368 - val_mean_loss: 89.0724 - val_std_loss: 26.4454\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 92.39170\n",
      "Epoch 23/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 90.3351 - sequence_loss: 90.3475 - mean_loss: 85.6931 - std_loss: 26.4616 - val_loss: 90.9656 - val_sequence_loss: 90.9610 - val_mean_loss: 86.4195 - val_std_loss: 26.2557\n",
      "\n",
      "Epoch 00023: val_loss improved from 92.39170 to 90.96559, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 24/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 86.2110 - sequence_loss: 86.2262 - mean_loss: 81.2509 - std_loss: 26.4060 - val_loss: 88.2576 - val_sequence_loss: 88.2590 - val_mean_loss: 83.2630 - val_std_loss: 26.5313\n",
      "\n",
      "Epoch 00024: val_loss improved from 90.96559 to 88.25760, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6786/6786 [==============================] - 6s 912us/step - loss: 86.0214 - sequence_loss: 86.0147 - mean_loss: 81.0001 - std_loss: 26.4784 - val_loss: 89.3087 - val_sequence_loss: 89.3140 - val_mean_loss: 84.5219 - val_std_loss: 26.3888\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 88.25760\n",
      "Epoch 26/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 84.3739 - sequence_loss: 84.3807 - mean_loss: 79.3033 - std_loss: 26.5169 - val_loss: 86.2915 - val_sequence_loss: 86.2972 - val_mean_loss: 81.3618 - val_std_loss: 26.6205\n",
      "\n",
      "Epoch 00026: val_loss improved from 88.25760 to 86.29145, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 27/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 83.5520 - sequence_loss: 83.5300 - mean_loss: 78.3518 - std_loss: 26.5878 - val_loss: 85.4789 - val_sequence_loss: 85.4830 - val_mean_loss: 80.4638 - val_std_loss: 26.6815\n",
      "\n",
      "Epoch 00027: val_loss improved from 86.29145 to 85.47894, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 28/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 82.9180 - sequence_loss: 82.9056 - mean_loss: 77.6518 - std_loss: 26.4245 - val_loss: 88.0047 - val_sequence_loss: 88.0107 - val_mean_loss: 83.2890 - val_std_loss: 26.8953\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 85.47894\n",
      "Epoch 29/300\n",
      "6786/6786 [==============================] - 6s 918us/step - loss: 82.5805 - sequence_loss: 82.5877 - mean_loss: 77.3698 - std_loss: 26.7626 - val_loss: 85.2507 - val_sequence_loss: 85.2566 - val_mean_loss: 80.2992 - val_std_loss: 26.8532\n",
      "\n",
      "Epoch 00029: val_loss improved from 85.47894 to 85.25071, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 30/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 81.4266 - sequence_loss: 81.4234 - mean_loss: 76.0270 - std_loss: 26.7516 - val_loss: 85.4429 - val_sequence_loss: 85.4481 - val_mean_loss: 80.7520 - val_std_loss: 27.1226\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 85.25071\n",
      "Epoch 31/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 80.7305 - sequence_loss: 80.7400 - mean_loss: 75.3590 - std_loss: 26.7063 - val_loss: 83.1495 - val_sequence_loss: 83.1551 - val_mean_loss: 77.9914 - val_std_loss: 26.7057\n",
      "\n",
      "Epoch 00031: val_loss improved from 85.25071 to 83.14950, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 32/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 80.4868 - sequence_loss: 80.5043 - mean_loss: 75.1706 - std_loss: 26.5875 - val_loss: 85.6467 - val_sequence_loss: 85.6505 - val_mean_loss: 81.1171 - val_std_loss: 26.9154\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 83.14950\n",
      "Epoch 33/300\n",
      "6786/6786 [==============================] - 6s 917us/step - loss: 80.7272 - sequence_loss: 80.7485 - mean_loss: 75.3327 - std_loss: 26.6372 - val_loss: 86.5477 - val_sequence_loss: 86.5466 - val_mean_loss: 81.7015 - val_std_loss: 26.5096\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 83.14950\n",
      "Epoch 34/300\n",
      "6786/6786 [==============================] - 6s 911us/step - loss: 80.8100 - sequence_loss: 80.8107 - mean_loss: 75.4903 - std_loss: 26.5406 - val_loss: 82.0465 - val_sequence_loss: 82.0429 - val_mean_loss: 76.6548 - val_std_loss: 26.4154\n",
      "\n",
      "Epoch 00034: val_loss improved from 83.14950 to 82.04645, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 35/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 79.9615 - sequence_loss: 79.9506 - mean_loss: 74.5221 - std_loss: 26.7281 - val_loss: 82.1445 - val_sequence_loss: 82.1482 - val_mean_loss: 77.0264 - val_std_loss: 26.8696\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 82.04645\n",
      "Epoch 36/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 78.6272 - sequence_loss: 78.6568 - mean_loss: 73.1255 - std_loss: 26.6958 - val_loss: 81.0456 - val_sequence_loss: 81.0487 - val_mean_loss: 75.7183 - val_std_loss: 26.8517\n",
      "\n",
      "Epoch 00036: val_loss improved from 82.04645 to 81.04558, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 37/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 78.0105 - sequence_loss: 77.9984 - mean_loss: 72.4298 - std_loss: 26.7907 - val_loss: 80.4417 - val_sequence_loss: 80.4343 - val_mean_loss: 74.9229 - val_std_loss: 26.4820\n",
      "\n",
      "Epoch 00037: val_loss improved from 81.04558 to 80.44165, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 38/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 79.2344 - sequence_loss: 79.2130 - mean_loss: 73.8847 - std_loss: 26.7448 - val_loss: 83.4047 - val_sequence_loss: 83.4026 - val_mean_loss: 78.5156 - val_std_loss: 26.7787\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 80.44165\n",
      "Epoch 39/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 79.8185 - sequence_loss: 79.8311 - mean_loss: 74.4517 - std_loss: 26.6661 - val_loss: 80.4914 - val_sequence_loss: 80.4825 - val_mean_loss: 74.8988 - val_std_loss: 26.5009\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 80.44165\n",
      "Epoch 40/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 80.9325 - sequence_loss: 80.9330 - mean_loss: 75.6043 - std_loss: 26.6182 - val_loss: 87.4792 - val_sequence_loss: 87.4731 - val_mean_loss: 83.1814 - val_std_loss: 27.1763\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 80.44165\n",
      "Epoch 41/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 78.0765 - sequence_loss: 78.0568 - mean_loss: 72.4687 - std_loss: 26.8803 - val_loss: 78.6195 - val_sequence_loss: 78.6123 - val_mean_loss: 73.1951 - val_std_loss: 27.2017\n",
      "\n",
      "Epoch 00041: val_loss improved from 80.44165 to 78.61954, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 42/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 77.2923 - sequence_loss: 77.2835 - mean_loss: 71.6710 - std_loss: 27.1473 - val_loss: 76.6543 - val_sequence_loss: 76.6405 - val_mean_loss: 70.7188 - val_std_loss: 26.8180\n",
      "\n",
      "Epoch 00042: val_loss improved from 78.61954 to 76.65432, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 43/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 75.1782 - sequence_loss: 75.1828 - mean_loss: 69.4203 - std_loss: 27.0988 - val_loss: 75.8080 - val_sequence_loss: 75.7980 - val_mean_loss: 69.8440 - val_std_loss: 26.9101\n",
      "\n",
      "Epoch 00043: val_loss improved from 76.65432 to 75.80803, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 44/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 74.4653 - sequence_loss: 74.4570 - mean_loss: 68.5370 - std_loss: 27.1531 - val_loss: 77.3830 - val_sequence_loss: 77.3685 - val_mean_loss: 71.2292 - val_std_loss: 26.9214\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 75.80803\n",
      "Epoch 45/300\n",
      "6786/6786 [==============================] - 6s 909us/step - loss: 74.7662 - sequence_loss: 74.7583 - mean_loss: 68.7660 - std_loss: 27.3922 - val_loss: 76.4961 - val_sequence_loss: 76.4807 - val_mean_loss: 70.2101 - val_std_loss: 26.9653\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 75.80803\n",
      "Epoch 46/300\n",
      "6786/6786 [==============================] - 6s 918us/step - loss: 75.1010 - sequence_loss: 75.1130 - mean_loss: 69.3115 - std_loss: 27.1055 - val_loss: 75.6388 - val_sequence_loss: 75.6249 - val_mean_loss: 69.5650 - val_std_loss: 27.0703\n",
      "\n",
      "Epoch 00046: val_loss improved from 75.80803 to 75.63875, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 47/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 73.7457 - sequence_loss: 73.7657 - mean_loss: 67.7639 - std_loss: 27.2844 - val_loss: 76.8040 - val_sequence_loss: 76.7869 - val_mean_loss: 70.5428 - val_std_loss: 27.1429\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 75.63875\n",
      "Epoch 48/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 72.6082 - sequence_loss: 72.6127 - mean_loss: 66.4572 - std_loss: 27.4648 - val_loss: 75.1262 - val_sequence_loss: 75.1113 - val_mean_loss: 68.8439 - val_std_loss: 27.5565\n",
      "\n",
      "Epoch 00048: val_loss improved from 75.63875 to 75.12620, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 49/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 72.9511 - sequence_loss: 72.9416 - mean_loss: 66.8901 - std_loss: 27.5645 - val_loss: 75.2569 - val_sequence_loss: 75.2469 - val_mean_loss: 69.4968 - val_std_loss: 27.5942\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 75.12620\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6786/6786 [==============================] - 6s 914us/step - loss: 74.2833 - sequence_loss: 74.2655 - mean_loss: 68.1311 - std_loss: 27.3171 - val_loss: 78.9675 - val_sequence_loss: 78.9563 - val_mean_loss: 73.8121 - val_std_loss: 27.2567\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 75.12620\n",
      "Epoch 51/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 72.1500 - sequence_loss: 72.1501 - mean_loss: 65.9412 - std_loss: 27.4833 - val_loss: 76.2006 - val_sequence_loss: 76.1891 - val_mean_loss: 70.5374 - val_std_loss: 27.5677\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 75.12620\n",
      "Epoch 52/300\n",
      "6786/6786 [==============================] - 6s 918us/step - loss: 73.1105 - sequence_loss: 73.1039 - mean_loss: 66.9552 - std_loss: 27.4045 - val_loss: 74.7801 - val_sequence_loss: 74.7681 - val_mean_loss: 68.9098 - val_std_loss: 27.4406\n",
      "\n",
      "Epoch 00052: val_loss improved from 75.12620 to 74.78012, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 53/300\n",
      "6786/6786 [==============================] - 6s 909us/step - loss: 72.0827 - sequence_loss: 72.0755 - mean_loss: 65.8804 - std_loss: 27.6808 - val_loss: 74.9152 - val_sequence_loss: 74.9072 - val_mean_loss: 69.2620 - val_std_loss: 27.6519\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 74.78012\n",
      "Epoch 54/300\n",
      "6786/6786 [==============================] - 6s 918us/step - loss: 72.4841 - sequence_loss: 72.4861 - mean_loss: 66.3677 - std_loss: 27.7269 - val_loss: 73.4253 - val_sequence_loss: 73.4146 - val_mean_loss: 67.1316 - val_std_loss: 27.6212\n",
      "\n",
      "Epoch 00054: val_loss improved from 74.78012 to 73.42534, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 55/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 71.3541 - sequence_loss: 71.3518 - mean_loss: 64.9393 - std_loss: 27.7986 - val_loss: 74.3870 - val_sequence_loss: 74.3753 - val_mean_loss: 68.3264 - val_std_loss: 27.4671\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 73.42534\n",
      "Epoch 56/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 72.0980 - sequence_loss: 72.0816 - mean_loss: 65.7488 - std_loss: 27.7211 - val_loss: 72.9278 - val_sequence_loss: 72.9213 - val_mean_loss: 66.6022 - val_std_loss: 27.7757\n",
      "\n",
      "Epoch 00056: val_loss improved from 73.42534 to 72.92780, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 57/300\n",
      "6786/6786 [==============================] - 6s 911us/step - loss: 72.1047 - sequence_loss: 72.1044 - mean_loss: 65.8917 - std_loss: 27.7307 - val_loss: 73.0256 - val_sequence_loss: 73.0176 - val_mean_loss: 66.6842 - val_std_loss: 27.8568\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 72.92780\n",
      "Epoch 58/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 71.8527 - sequence_loss: 71.8503 - mean_loss: 65.5472 - std_loss: 28.0445 - val_loss: 72.8244 - val_sequence_loss: 72.8159 - val_mean_loss: 66.3716 - val_std_loss: 28.0351\n",
      "\n",
      "Epoch 00058: val_loss improved from 72.92780 to 72.82439, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 59/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 72.1612 - sequence_loss: 72.1404 - mean_loss: 65.8693 - std_loss: 27.9042 - val_loss: 80.4623 - val_sequence_loss: 80.4439 - val_mean_loss: 74.8087 - val_std_loss: 27.7218\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 72.82439\n",
      "Epoch 60/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 72.7869 - sequence_loss: 72.7878 - mean_loss: 66.5875 - std_loss: 27.7985 - val_loss: 81.3699 - val_sequence_loss: 81.3511 - val_mean_loss: 75.7920 - val_std_loss: 27.3447\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 72.82439\n",
      "Epoch 61/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 72.2299 - sequence_loss: 72.2406 - mean_loss: 65.9902 - std_loss: 27.8340 - val_loss: 74.3578 - val_sequence_loss: 74.3471 - val_mean_loss: 68.4344 - val_std_loss: 28.0513\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 72.82439\n",
      "Epoch 62/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 70.9247 - sequence_loss: 70.9293 - mean_loss: 64.5145 - std_loss: 27.8801 - val_loss: 76.5038 - val_sequence_loss: 76.4971 - val_mean_loss: 71.0844 - val_std_loss: 28.0301\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 72.82439\n",
      "Epoch 63/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 70.9976 - sequence_loss: 71.0072 - mean_loss: 64.5781 - std_loss: 27.8765 - val_loss: 73.2726 - val_sequence_loss: 73.2594 - val_mean_loss: 66.9930 - val_std_loss: 28.0175\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 72.82439\n",
      "Epoch 64/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 70.5163 - sequence_loss: 70.5351 - mean_loss: 63.9515 - std_loss: 27.9000 - val_loss: 73.9547 - val_sequence_loss: 73.9492 - val_mean_loss: 67.5377 - val_std_loss: 27.8280\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 72.82439\n",
      "Epoch 65/300\n",
      "6786/6786 [==============================] - 6s 909us/step - loss: 77.5583 - sequence_loss: 77.5579 - mean_loss: 71.7322 - std_loss: 27.4722 - val_loss: 73.8903 - val_sequence_loss: 73.8843 - val_mean_loss: 67.5876 - val_std_loss: 27.8356\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 72.82439\n",
      "Epoch 66/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 74.3861 - sequence_loss: 74.3801 - mean_loss: 68.3107 - std_loss: 27.8281 - val_loss: 74.6132 - val_sequence_loss: 74.6043 - val_mean_loss: 68.6936 - val_std_loss: 27.6509\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 72.82439\n",
      "Epoch 67/300\n",
      "6786/6786 [==============================] - 6s 917us/step - loss: 73.0350 - sequence_loss: 73.0125 - mean_loss: 66.8402 - std_loss: 27.6218 - val_loss: 73.2347 - val_sequence_loss: 73.2227 - val_mean_loss: 67.0208 - val_std_loss: 27.9075\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 72.82439\n",
      "Epoch 68/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 71.0286 - sequence_loss: 71.0270 - mean_loss: 64.5690 - std_loss: 27.7770 - val_loss: 73.3646 - val_sequence_loss: 73.3500 - val_mean_loss: 67.2881 - val_std_loss: 27.8965\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 72.82439\n",
      "Epoch 69/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 70.4703 - sequence_loss: 70.4807 - mean_loss: 63.9598 - std_loss: 27.7335 - val_loss: 72.9175 - val_sequence_loss: 72.9054 - val_mean_loss: 66.6058 - val_std_loss: 27.6555\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 72.82439\n",
      "Epoch 70/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 70.7053 - sequence_loss: 70.7174 - mean_loss: 64.3274 - std_loss: 27.7081 - val_loss: 71.9293 - val_sequence_loss: 71.9141 - val_mean_loss: 65.4408 - val_std_loss: 27.4977\n",
      "\n",
      "Epoch 00070: val_loss improved from 72.82439 to 71.92927, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 71/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 70.4904 - sequence_loss: 70.5008 - mean_loss: 63.9895 - std_loss: 27.8080 - val_loss: 72.8767 - val_sequence_loss: 72.8661 - val_mean_loss: 66.6138 - val_std_loss: 27.7397\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 71.92927\n",
      "Epoch 72/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 70.4337 - sequence_loss: 70.4377 - mean_loss: 63.9517 - std_loss: 27.9951 - val_loss: 72.1227 - val_sequence_loss: 72.1122 - val_mean_loss: 65.6939 - val_std_loss: 27.7182\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 71.92927\n",
      "Epoch 73/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 70.2825 - sequence_loss: 70.2972 - mean_loss: 63.7071 - std_loss: 28.0818 - val_loss: 72.1216 - val_sequence_loss: 72.1076 - val_mean_loss: 65.7013 - val_std_loss: 27.9829\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 71.92927\n",
      "Epoch 74/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 71.5496 - sequence_loss: 71.5475 - mean_loss: 65.1913 - std_loss: 27.9804 - val_loss: 72.7970 - val_sequence_loss: 72.7841 - val_mean_loss: 66.5099 - val_std_loss: 27.8442\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 71.92927\n",
      "Epoch 75/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 70.1470 - sequence_loss: 70.1396 - mean_loss: 63.6206 - std_loss: 28.1331 - val_loss: 73.6955 - val_sequence_loss: 73.6899 - val_mean_loss: 67.7102 - val_std_loss: 28.0487\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 71.92927\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6786/6786 [==============================] - 6s 916us/step - loss: 71.0191 - sequence_loss: 70.9974 - mean_loss: 64.6621 - std_loss: 28.0280 - val_loss: 72.5670 - val_sequence_loss: 72.5578 - val_mean_loss: 66.2405 - val_std_loss: 27.9827\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 71.92927\n",
      "Epoch 77/300\n",
      "6786/6786 [==============================] - 6s 920us/step - loss: 70.2031 - sequence_loss: 70.2077 - mean_loss: 63.7862 - std_loss: 27.7644 - val_loss: 75.9619 - val_sequence_loss: 75.9546 - val_mean_loss: 70.3504 - val_std_loss: 27.6573\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 71.92927\n",
      "Epoch 78/300\n",
      "6786/6786 [==============================] - 6s 917us/step - loss: 70.3751 - sequence_loss: 70.3650 - mean_loss: 63.8670 - std_loss: 27.9604 - val_loss: 72.5399 - val_sequence_loss: 72.5310 - val_mean_loss: 66.1479 - val_std_loss: 28.1846\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 71.92927\n",
      "Epoch 79/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 70.8933 - sequence_loss: 70.8974 - mean_loss: 64.5263 - std_loss: 27.8830 - val_loss: 74.5303 - val_sequence_loss: 74.5153 - val_mean_loss: 68.6357 - val_std_loss: 27.8591\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 71.92927\n",
      "Epoch 80/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 71.1003 - sequence_loss: 71.0971 - mean_loss: 64.7832 - std_loss: 27.8256 - val_loss: 71.5613 - val_sequence_loss: 71.5486 - val_mean_loss: 65.1302 - val_std_loss: 27.6269\n",
      "\n",
      "Epoch 00080: val_loss improved from 71.92927 to 71.56126, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 81/300\n",
      "6786/6786 [==============================] - 6s 911us/step - loss: 70.2726 - sequence_loss: 70.2683 - mean_loss: 63.8220 - std_loss: 27.6693 - val_loss: 71.9002 - val_sequence_loss: 71.8944 - val_mean_loss: 65.3396 - val_std_loss: 27.9722\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 71.56126\n",
      "Epoch 82/300\n",
      "6786/6786 [==============================] - 6s 913us/step - loss: 70.0747 - sequence_loss: 70.0955 - mean_loss: 63.5649 - std_loss: 27.8625 - val_loss: 73.5368 - val_sequence_loss: 73.5219 - val_mean_loss: 67.1140 - val_std_loss: 27.6060\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 71.56126\n",
      "Epoch 83/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 69.7553 - sequence_loss: 69.7512 - mean_loss: 63.2575 - std_loss: 27.9129 - val_loss: 72.2888 - val_sequence_loss: 72.2815 - val_mean_loss: 65.8233 - val_std_loss: 27.8892\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 71.56126\n",
      "Epoch 84/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 69.1810 - sequence_loss: 69.1802 - mean_loss: 62.4925 - std_loss: 27.9027 - val_loss: 73.1545 - val_sequence_loss: 73.1459 - val_mean_loss: 66.9737 - val_std_loss: 27.7757\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 71.56126\n",
      "Epoch 85/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 69.3467 - sequence_loss: 69.3560 - mean_loss: 62.7985 - std_loss: 27.7995 - val_loss: 72.8587 - val_sequence_loss: 72.8419 - val_mean_loss: 66.5495 - val_std_loss: 27.8506\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 71.56126\n",
      "Epoch 86/300\n",
      "6786/6786 [==============================] - 6s 917us/step - loss: 69.4392 - sequence_loss: 69.4471 - mean_loss: 62.8987 - std_loss: 27.7696 - val_loss: 71.3944 - val_sequence_loss: 71.3825 - val_mean_loss: 64.7057 - val_std_loss: 27.8282\n",
      "\n",
      "Epoch 00086: val_loss improved from 71.56126 to 71.39436, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 87/300\n",
      "6786/6786 [==============================] - 6s 910us/step - loss: 70.9512 - sequence_loss: 70.9428 - mean_loss: 64.5233 - std_loss: 27.7072 - val_loss: 73.2690 - val_sequence_loss: 73.2569 - val_mean_loss: 66.9207 - val_std_loss: 27.4510\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 71.39436\n",
      "Epoch 88/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 70.1842 - sequence_loss: 70.1981 - mean_loss: 63.6956 - std_loss: 27.7122 - val_loss: 77.3766 - val_sequence_loss: 77.3720 - val_mean_loss: 71.9474 - val_std_loss: 27.9314\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 71.39436\n",
      "Epoch 89/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 69.5624 - sequence_loss: 69.5742 - mean_loss: 62.9936 - std_loss: 27.7660 - val_loss: 73.1233 - val_sequence_loss: 73.1108 - val_mean_loss: 67.0199 - val_std_loss: 28.0458\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 71.39436\n",
      "Epoch 90/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 68.9971 - sequence_loss: 68.9806 - mean_loss: 62.2976 - std_loss: 27.8094 - val_loss: 72.3515 - val_sequence_loss: 72.3435 - val_mean_loss: 65.9059 - val_std_loss: 27.6855\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 71.39436\n",
      "Epoch 91/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 70.2895 - sequence_loss: 70.2905 - mean_loss: 63.9326 - std_loss: 27.7828 - val_loss: 77.5795 - val_sequence_loss: 77.5764 - val_mean_loss: 72.1394 - val_std_loss: 27.9173\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 71.39436\n",
      "Epoch 92/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 69.1181 - sequence_loss: 69.0959 - mean_loss: 62.4384 - std_loss: 27.8157 - val_loss: 71.7217 - val_sequence_loss: 71.7124 - val_mean_loss: 65.1084 - val_std_loss: 27.8827\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 71.39436\n",
      "Epoch 93/300\n",
      "6786/6786 [==============================] - 6s 908us/step - loss: 68.5695 - sequence_loss: 68.5558 - mean_loss: 61.8473 - std_loss: 27.9309 - val_loss: 71.0623 - val_sequence_loss: 71.0486 - val_mean_loss: 64.2772 - val_std_loss: 27.9186\n",
      "\n",
      "Epoch 00093: val_loss improved from 71.39436 to 71.06227, saving model to ../models/base_LSTM.hdf5\n",
      "Epoch 94/300\n",
      "6786/6786 [==============================] - 6s 912us/step - loss: 69.4974 - sequence_loss: 69.4984 - mean_loss: 62.9031 - std_loss: 27.9565 - val_loss: 71.1185 - val_sequence_loss: 71.1065 - val_mean_loss: 64.3692 - val_std_loss: 28.0606\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 71.06227\n",
      "Epoch 95/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 70.1561 - sequence_loss: 70.1537 - mean_loss: 63.6137 - std_loss: 28.2041 - val_loss: 76.0771 - val_sequence_loss: 76.0591 - val_mean_loss: 70.2974 - val_std_loss: 28.2749\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 71.06227\n",
      "Epoch 96/300\n",
      "6786/6786 [==============================] - 6s 911us/step - loss: 69.4947 - sequence_loss: 69.4873 - mean_loss: 62.9405 - std_loss: 28.3411 - val_loss: 71.7345 - val_sequence_loss: 71.7273 - val_mean_loss: 65.2436 - val_std_loss: 28.0264\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 71.06227\n",
      "Epoch 97/300\n",
      "6786/6786 [==============================] - 6s 915us/step - loss: 69.1609 - sequence_loss: 69.1423 - mean_loss: 62.4503 - std_loss: 27.9019 - val_loss: 71.8106 - val_sequence_loss: 71.7989 - val_mean_loss: 65.3624 - val_std_loss: 28.1312\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 71.06227\n",
      "Epoch 98/300\n",
      "6786/6786 [==============================] - 6s 917us/step - loss: 71.0320 - sequence_loss: 71.0385 - mean_loss: 64.6309 - std_loss: 27.8498 - val_loss: 73.3844 - val_sequence_loss: 73.3753 - val_mean_loss: 67.2275 - val_std_loss: 27.7068\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 71.06227\n",
      "Epoch 99/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 68.9717 - sequence_loss: 68.9719 - mean_loss: 62.2623 - std_loss: 27.9446 - val_loss: 73.0613 - val_sequence_loss: 73.0536 - val_mean_loss: 66.6046 - val_std_loss: 27.9741\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 71.06227\n",
      "Epoch 100/300\n",
      "6786/6786 [==============================] - 6s 916us/step - loss: 69.4343 - sequence_loss: 69.4377 - mean_loss: 62.8308 - std_loss: 27.7716 - val_loss: 71.9501 - val_sequence_loss: 71.9369 - val_mean_loss: 65.3289 - val_std_loss: 27.8122\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 71.06227\n",
      "Epoch 101/300\n",
      "6786/6786 [==============================] - 6s 914us/step - loss: 69.9722 - sequence_loss: 69.9838 - mean_loss: 63.4950 - std_loss: 27.8837 - val_loss: 73.9663 - val_sequence_loss: 73.9585 - val_mean_loss: 67.8777 - val_std_loss: 27.7881\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 71.06227\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6786/6786 [==============================] - 6s 911us/step - loss: 68.7657 - sequence_loss: 68.7881 - mean_loss: 61.9857 - std_loss: 28.0903 - val_loss: 71.8053 - val_sequence_loss: 71.7960 - val_mean_loss: 65.2196 - val_std_loss: 28.1542\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 71.06227\n",
      "Epoch 103/300\n",
      "6700/6786 [============================>.] - ETA: 0s - loss: 68.3142 - sequence_loss: 68.3142 - mean_loss: 61.4826 - std_loss: 28.0932"
     ]
    }
   ],
   "source": [
    "filepath = '../models/base_LSTM.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=30)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = sequence_autoencoder.fit(X_train, [y_train,means_train,stds_train],\n",
    "                epochs=300,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val,[y_val,means_val,stds_val]),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "sequence_autoencoder = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = sequence_autoencoder.predict(X_test)\n",
    "y_pred = y_pred1[0]\n",
    "mean_pred = y_pred1[1]\n",
    "stds_pred = y_pred1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1[0].shape,y_pred1[1].shape,y_pred1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(y[-10])\n",
    "for i,a in enumerate(y_pred[::-1][200:240]):\n",
    "#     if np.sum(a)>0:\n",
    "    plt.figure()\n",
    "    plt.plot(a,'g')\n",
    "#         plt.plot(X[i,:,:],'r')\n",
    "    plt.plot(y_test[i],'b')\n",
    "    plt.plot(ecg_test[i],'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(quals_test.reshape(-1)),4))\n",
    "X[:,0] = quals_test.reshape(-1)\n",
    "X[:,1] = y_pred.reshape(-1)\n",
    "X[:,2] = ecg_test.reshape(-1)\n",
    "X[:,3] = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X[:,0]>-1]\n",
    "X = X[X[:,2]>0]\n",
    "X = X[X[:,3]>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_range = np.arange(0,1,.05)\n",
    "x = []\n",
    "y = []\n",
    "y1 = []\n",
    "for l in l_range:\n",
    "    index = np.where((X[:,0]>=l)&(X[:,0]<l+.05))[0]\n",
    "    temp = X[index]\n",
    "    print(temp.shape,l)\n",
    "    x.append(str(np.round(l*100)/100)+'-'+str(np.round((l+.05)*100)/100))\n",
    "    y.append(list(np.abs(temp[:,2]-temp[:,3])))\n",
    "    a = np.array(np.abs(temp[:,1]-temp[:,2]))\n",
    "    y1.append(a[~np.isnan(a)])\n",
    "print(len(y),len(y1))\n",
    "#     print(np.mean(np.abs(temp[:,0]-temp[:,2])),np.std(np.abs(temp[:,0]-temp[:,2])),len(index))\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size':20})\n",
    "c = plt.boxplot(y,showfliers=False,positions=np.array(range(0,3*len(y),3)),notch=True)\n",
    "for box in c['boxes']:\n",
    "    box.set(color='red', linewidth=1)\n",
    "b = plt.boxplot(y1,showfliers=False,positions=np.array(range(0,3*len(y),3))+1.5,notch=True)\n",
    "for box in b['boxes']:\n",
    "    box.set(color='blue', linewidth=1)\n",
    "#     box.set(facecolor = 'red' )\n",
    "plt.xticks(np.array(range(0,3*len(y),3)),x,rotation=60)\n",
    "plt.ylabel('Absolute Difference in Milliseconds')\n",
    "plt.xlabel('Range of Signal Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrvanalysis import get_time_domain_features\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "q = []\n",
    "s = 'rmssd'\n",
    "for i in range(ecg_test.shape[0]):\n",
    "    qual_min = quals_test[i].reshape(-1)\n",
    "    qual_min = qual_min[qual_min>-1]\n",
    "    ecg_min = ecg_test[i].reshape(-1)\n",
    "    ecg_min = ecg_min[ecg_min>0]\n",
    "    ecg_min= ecg_min[~np.isnan(ecg_min)]\n",
    "    y_pred_min = y_pred[i].reshape(-1)\n",
    "    y_pred_min = y_pred_min[~np.isnan(y_pred_min)]\n",
    "    y_test_min = y_test[i].reshape(-1)\n",
    "    y_test_min = y_test_min[y_test_min>0]\n",
    "    y_test_min = y_test_min[~np.isnan(y_test_min)]\n",
    "    if len(ecg_min)<10 or len(y_pred_min)<5 or len(y_test_min)<5:\n",
    "        continue\n",
    "    x.append(get_time_domain_features(y_pred_min)[s])\n",
    "    y.append(get_time_domain_features(ecg_min)[s])\n",
    "    z.append(get_time_domain_features(y_test_min)[s])\n",
    "    q.append(np.median(qual_min))\n",
    "    if np.isinf(x[-1]) or np.isinf(y[-1]) or np.isinf(z[-1]) or np.isinf(q[-1]):\n",
    "        x = x[:-1]\n",
    "        y= y[:-1]\n",
    "        z= z[:-1]\n",
    "        q= q[:-1]\n",
    "    elif np.isnan(x[-1]) or np.isnan(y[-1]) or np.isnan(z[-1]) or np.isnan(q[-1]):\n",
    "        x = x[:-1]\n",
    "        y= y[:-1]\n",
    "        z= z[:-1]\n",
    "        q= q[:-1]\n",
    "#     print(np.std(ecg_min),np.std(y_test_min),np.std(y_pred_min),np.median(qual_min))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,spearmanr\n",
    "q,x,y,z = np.array(q),np.array(x),np.array(y),np.array(z)\n",
    "for i in np.linspace(0,.9,10):\n",
    "    index = np.where((q>=i)&(q<=i+.1))[0]\n",
    "    if len(index)<2:\n",
    "        continue\n",
    "    print(pearsonr(x[index],y[index]),pearsonr(y[index],z[index]),i,i+.1,len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(y.reshape(-1),50)\n",
    "plt.hist(y_pred.reshape(-1),50)\n",
    "plt.hist(ecg_test.reshape(-1),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y[0].reshape(1,-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred1[1].reshape(-1),means_test.reshape(-1),'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(y_pred1[1].reshape(-1),means_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[np.isfinite(t)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(quals_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
