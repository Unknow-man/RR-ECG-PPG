{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# data = pickle.load(open('../data/leftppgecg.p','rb'))\n",
    "directory = '../data_users/ecg_ppg/'\n",
    "dfs = []\n",
    "for f in os.listdir(directory)[:50]:\n",
    "    if f[-1]!='p':\n",
    "        continue\n",
    "    a = pickle.load(open(directory+f,'rb'))\n",
    "    print(a.shape,end=',')\n",
    "    dfs.append(a)\n",
    "print()\n",
    "data1 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "data_all = deepcopy(data1)\n",
    "\n",
    "data_all['red_rr'] = data_all['ppg_rr'].apply(lambda x:x[0])\n",
    "data_all['ir_rr'] = data_all['ppg_rr'].apply(lambda x:x[1])\n",
    "data_all['green_rr'] = data_all['ppg_rr'].apply(lambda x:x[2])\n",
    "data_all['red_qual'] = data_all['likelihood'].apply(lambda x:x[0])\n",
    "data_all['ir_qual'] = data_all['likelihood'].apply(lambda x:x[1])\n",
    "data_all['green_qual'] = data_all['likelihood'].apply(lambda x:x[2])\n",
    "data_all['index'] = data_all['likelihood'].apply(lambda x:np.argmax(np.array(x)))\n",
    "values = data_all[['ppg_rr','index']].values\n",
    "values = [a[b] for a,b in values]\n",
    "data_all['ppg_rr_best'] = values\n",
    "data_all['likelihood_best'] = data_all['likelihood'].apply(lambda x:max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_all,open('../data_users/merged_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "data_all = pickle.load(open('../data_users/merged_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29536929, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from joblib import Parallel,delayed\n",
    "from hrvanalysis import get_time_domain_features\n",
    "\n",
    "from copy import deepcopy\n",
    "def get_data1(a):\n",
    "    features = []\n",
    "    ecg_rr = a[:,-1]\n",
    "    if len(ecg_rr[np.isnan(ecg_rr)])>20:\n",
    "        return [],[],[],[],[],[]\n",
    "    ecg_rr[np.isnan(ecg_rr)] = np.nanmean(ecg_rr)\n",
    "    m = np.mean(ecg_rr[ecg_rr>0])\n",
    "    s = np.mean(ecg_rr[ecg_rr>0])\n",
    "    if len(ecg_rr)<60:\n",
    "        return [],[],[],[],[],[]\n",
    "    y = []\n",
    "    X = []\n",
    "    ecg = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    quals = []\n",
    "    for i in [-2]:\n",
    "        ppg_rr = a[:,i]\n",
    "        ppg_qual = a[:,i-4]\n",
    "        index1 = ~np.isnan(ppg_rr)\n",
    "        if len(ppg_rr[index1])<30:\n",
    "            continue\n",
    "        index = np.isnan(ppg_rr)\n",
    "        ppg_qual[index] = -1\n",
    "        index = np.isnan(ppg_qual)\n",
    "        ppg_qual[index] = -1\n",
    "        tmp = a[:,np.array([-2,-3,-4,-5,-6,-7,-8,-9,1])].reshape(60,9)\n",
    "        for k in range(4):\n",
    "            tmp[np.isnan(tmp[:,k]),k] = np.nanmean(tmp[:,k])\n",
    "            tmp[tmp[:,k]==0,k] = np.mean(tmp[tmp[:,k]>0,k])\n",
    "        tmp[np.isnan(tmp)] = 0\n",
    "        y.append(tmp[:,0].reshape(1,60,1))\n",
    "        X.append(tmp.reshape(1,60,9))\n",
    "        means.append(m)\n",
    "        stds.append(s)\n",
    "        ecg.append(ecg_rr.reshape(1,60,1))\n",
    "        quals.append(ppg_qual.reshape(1,60,1))\n",
    "    return X,y,ecg,means,stds,quals\n",
    "\n",
    "unique_users = data_all['user'].unique()\n",
    "\n",
    "def get_data(name,df):\n",
    "    df = df[['time','activity','red_qual','ir_qual','green_qual','likelihood_best',\n",
    "             'red_rr','ir_rr','green_rr','ppg_rr_best','ecg_rr']].values\n",
    "    return df.reshape(-1,60,11)\n",
    "def get_all_data(data_user):\n",
    "    data_user.set_index('timestamp',inplace=True)\n",
    "    convert_dict = {'ecg_rr': float}\n",
    "    data_user = data_user.astype(convert_dict) \n",
    "    data_resampled = data_user.resample('1S').mean()\n",
    "    if 'ecg_rr' not in np.array(data_resampled.columns.values):\n",
    "        return []\n",
    "    df_col = [get_data(group_name, df_group) for group_name, df_group\n",
    "                                           in data_resampled.groupby(pd.Grouper(freq='60S')) if df_group.shape[0]==60]\n",
    "    df_user = np.concatenate(df_col)\n",
    "    df_col = [get_data1(a) for a in df_user if len(a[~np.isnan(a[:,-1]),-1])>20]\n",
    "    return df_col\n",
    "# for user in unique_users:\n",
    "#     data_user = data_all[data_all.user.isin([user])]\n",
    "all_X = Parallel(n_jobs=20,verbose=3)(delayed(get_all_data)(data_all[data_all.user.isin([user])]) for user in unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = [],[],[],[],[],[]\n",
    "for i,b in enumerate(all_X):\n",
    "    if len(b)==0:\n",
    "        continue\n",
    "    for a in b:\n",
    "        X.extend(a[0])\n",
    "        y.extend(a[1])\n",
    "        ecg.extend(a[2])\n",
    "        means.extend(a[3])\n",
    "        stds.extend(a[4])\n",
    "        quals.extend(a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([X,y,ecg,means,stds,quals],open('../data_users/processed_data.p','wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "X,y,ecg,means,stds,quals = pickle.load(open('../data_users/processed_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ecg,means,stds,quals = np.concatenate(X),np.concatenate(y).reshape(-1,60),np.concatenate(ecg).reshape(-1,60),\\\n",
    "np.array(means).reshape(-1,1),np.array(stds).reshape(-1,1),np.concatenate(quals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector,Bidirectional,Multiply,multiply,Permute\n",
    "from keras.layers import TimeDistributed,Dense,Flatten,Reshape,Lambda,Activation,GRU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras import metrics,losses\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "X_train, X_test, y_train, y_test,ecg_train, \\\n",
    "ecg_test,means_train,means_test,stds_train,stds_test, \\\n",
    "quals_train,quals_test= train_test_split(\n",
    "    X[:,:,np.array([0,4])], y,ecg,means,stds,quals, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val,means_train,means_val,stds_train,stds_val = train_test_split(\n",
    "    X_train, y_train,means_train,stds_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_test.shape,y_val.shape,means_val.shape,stds_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_of_lambda(input_shape):\n",
    "    return (input_shape[0], 1)\n",
    "\n",
    "def mean(x):\n",
    "    return K.mean(x,axis=1,keepdims=True)\n",
    "\n",
    "def output_of_lambda1(input_shape):\n",
    "    return (input_shape[0], 1)\n",
    "\n",
    "def mean1(x):\n",
    "    return K.mean(x,axis=1,keepdims=True)\n",
    "\n",
    "timesteps = 60\n",
    "input_dim = 2\n",
    "latent_dim = 20\n",
    "output_dim = 1\n",
    "n = 1\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "# inputs2 = Reshape((1,1))(inputs1)\n",
    "encoded = Bidirectional(GRU(60,return_sequences=True,activation='linear',go_backwards=True))(inputs)\n",
    "# encoded = LSTM(output_dim,return_sequences=True,activation='sigmoid')(encoded)\n",
    "att = Dense(1,activation='relu')(encoded)\n",
    "\n",
    "att = Flatten()(att)\n",
    "att = Activation(activation=\"softmax\")(att)\n",
    "att = RepeatVector(120)(att)\n",
    "att = Permute((2,1))(att)\n",
    "mer = multiply([att, encoded])\n",
    "\n",
    "# encoded = TimeDistributed(Dense(,activation='relu'))(mer)\n",
    "encoded = Flatten()(mer)\n",
    "encoded = Dense(10,activation='relu',name='sequence1')(encoded)\n",
    "encoded = Dense(60,activation='relu',name='sequence')(encoded)\n",
    "# encoded = Reshape((60),name='sequence')(encoded)\n",
    "# encoded_std = K.std(encoded,axis=1)\n",
    "decoded = Lambda(mean, output_shape=output_of_lambda,name='mean')(encoded)\n",
    "decoded1 = Lambda(mean1, output_shape=output_of_lambda1,name='std')(encoded)\n",
    "# decoded = LSTM(output_dim*60, return_sequences=True)(decoded)\n",
    "# decoded = LSTM(output_dim*3, return_sequences=True)(decoded)\n",
    "# decoded = LSTM(output_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs=[inputs], outputs=[encoded,decoded,decoded1])\n",
    "# encoder = Model(inputs, encoded)\n",
    "losses = {\n",
    "    \"std\":\"logcosh\",\n",
    "    \"mean\": \"logcosh\",\n",
    "    \"sequence\": \"logcosh\"\n",
    "}\n",
    "lossWeights = {\"mean\": 0, \"sequence\": 1,\"std\":0}\n",
    "# initialize the optimizer and compile the model\n",
    "\n",
    "sequence_autoencoder.compile(optimizer='adam',loss=losses, loss_weights=lossWeights)\n",
    "\n",
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = '../models/base_LSTM.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=30)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = sequence_autoencoder.fit(X_train, [y_train,means_train,stds_train],\n",
    "                epochs=300,\n",
    "                batch_size=500,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val,[y_val,means_val,stds_val]),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow_probability as tfp\n",
    "sequence_autoencoder = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = sequence_autoencoder.predict(X_test)\n",
    "y_pred = y_pred1[0]\n",
    "mean_pred = y_pred1[1]\n",
    "stds_pred = y_pred1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1[0].shape,y_pred1[1].shape,y_pred1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(y[-10])\n",
    "for i,a in enumerate(y_pred[:10]):\n",
    "#     if np.sum(a)>0:\n",
    "    plt.figure()\n",
    "    plt.plot(a,'g')\n",
    "    plt.plot(X_test[i,:,:4],'r')\n",
    "    plt.plot(y_test[i],'b')\n",
    "#     plt.plot(ecg_test[i],'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(quals_test.reshape(-1)),4))\n",
    "X[:,0] = quals_test.reshape(-1)\n",
    "X[:,1] = y_pred.reshape(-1)\n",
    "X[:,2] = ecg_test.reshape(-1)\n",
    "X[:,3] = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X[:,0]>-1]\n",
    "X = X[X[:,2]>0]\n",
    "X = X[X[:,3]>0]\n",
    "X = X[X[:,1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_range = np.arange(0,1,.05)\n",
    "x = []\n",
    "y = []\n",
    "y1 = []\n",
    "for l in l_range:\n",
    "    index = np.where((X[:,0]>=l)&(X[:,0]<l+.05))[0]\n",
    "    temp = X[index]\n",
    "    print(temp.shape,l)\n",
    "    x.append(str(np.round(l*100)/100)+'-'+str(np.round((l+.05)*100)/100))\n",
    "    y.append(list(np.abs(temp[:,2]-temp[:,3])))\n",
    "    a = np.array(np.abs(temp[:,1]-temp[:,2]))\n",
    "    y1.append(a[~np.isnan(a)])\n",
    "print(len(y),len(y1))\n",
    "#     print(np.mean(np.abs(temp[:,0]-temp[:,2])),np.std(np.abs(temp[:,0]-temp[:,2])),len(index))\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size':20})\n",
    "c = plt.boxplot(y,showfliers=False,positions=np.array(range(0,3*len(y),3)),notch=True)\n",
    "for box in c['boxes']:\n",
    "    box.set(color='red', linewidth=1)\n",
    "b = plt.boxplot(y1,showfliers=False,positions=np.array(range(0,3*len(y),3))+1.5,notch=True)\n",
    "for box in b['boxes']:\n",
    "    box.set(color='blue', linewidth=1)\n",
    "#     box.set(facecolor = 'red' )\n",
    "plt.xticks(np.array(range(0,3*len(y),3)),x,rotation=60)\n",
    "plt.ylabel('Absolute Difference in Milliseconds')\n",
    "plt.xlabel('Range of Signal Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrvanalysis import get_time_domain_features\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "q = []\n",
    "s = 'range_nni'\n",
    "for i in range(ecg_test.shape[0]):\n",
    "    qual_min = quals_test[i].reshape(-1)\n",
    "    qual_min = qual_min[qual_min>-1]\n",
    "    ecg_min = ecg_test[i].reshape(-1)\n",
    "    ecg_min = ecg_min[ecg_min>0]\n",
    "    ecg_min= ecg_min[~np.isnan(ecg_min)]\n",
    "    y_pred_min = y_pred[i].reshape(-1)\n",
    "    y_pred_min = y_pred_min[~np.isnan(y_pred_min)]\n",
    "    y_test_min = y_test[i].reshape(-1)\n",
    "    y_test_min = y_test_min[y_test_min>0]\n",
    "    y_test_min = y_test_min[~np.isnan(y_test_min)]\n",
    "    if len(ecg_min)<40 or len(y_pred_min)<30 or len(y_test_min)<30:\n",
    "        continue\n",
    "    x.append(np.array(list(get_time_domain_features(y_pred_min).values())))\n",
    "    y.append(np.array(list(get_time_domain_features(ecg_min).values())))\n",
    "    z.append(np.array(list(get_time_domain_features(y_test_min).values())))\n",
    "    q.append(np.mean(qual_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,ecgs,fpreds,q = np.array(x),np.array(y),np.array(z),np.array(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape,ecgs.shape,fpreds.shape,q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_col = ['mean_nni', 'sdnn', 'sdsd', 'nni_50', 'pnni_50', 'nni_20', 'pnni_20', 'rmssd',\n",
    " 'median_nni', 'range_nni', 'cvsd', 'cvnni', 'mean_hr', 'max_hr', 'min_hr', 'std_hr']\n",
    "for j in range(len(feature_col)):\n",
    "    x = []\n",
    "    y = []\n",
    "    y1 = []\n",
    "    for i in np.linspace(0,.9,10):\n",
    "        index = np.where((q>=i)&(q<=i+.10))[0]\n",
    "#         print(len(index))\n",
    "        if len(index)<10:\n",
    "            continue\n",
    "        x.append(str(i))\n",
    "#         print(pearsonr(ecgs[index,j],preds[index,j])[0])\n",
    "        y.append(pearsonr(ecgs[index,j],preds[index,j])[0])\n",
    "        y1.append(pearsonr(ecgs[index,j],fpreds[index,j])[0])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.bar(x,y,.5,label='Generative Model')\n",
    "    plt.bar(x,y1,.25,label='PPG Prediction')\n",
    "    plt.title(feature_col[j])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrvanalysis import get_time_domain_features\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "q = []\n",
    "s = 'rmssd'\n",
    "for i in range(ecg_test.shape[0]):\n",
    "    qual_min = quals_test[i].reshape(-1)\n",
    "    qual_min = qual_min[qual_min>-1]\n",
    "    ecg_min = ecg_test[i].reshape(-1)\n",
    "    ecg_min = ecg_min[ecg_min>0]\n",
    "    ecg_min= ecg_min[~np.isnan(ecg_min)]\n",
    "    y_pred_min = y_pred[i].reshape(-1)\n",
    "    y_pred_min = y_pred_min[~np.isnan(y_pred_min)]\n",
    "    y_test_min = y_test[i].reshape(-1)\n",
    "    y_test_min = y_test_min[y_test_min>0]\n",
    "    y_test_min = y_test_min[~np.isnan(y_test_min)]\n",
    "    if len(ecg_min)<10 or len(y_pred_min)<5 or len(y_test_min)<5:\n",
    "        continue\n",
    "    x.append(get_time_domain_features(y_pred_min)[s])\n",
    "    y.append(get_time_domain_features(ecg_min)[s])\n",
    "    z.append(get_time_domain_features(y_test_min)[s])\n",
    "    q.append(np.median(qual_min))\n",
    "    if np.isinf(x[-1]) or np.isinf(y[-1]) or np.isinf(z[-1]) or np.isinf(q[-1]):\n",
    "        x = x[:-1]\n",
    "        y= y[:-1]\n",
    "        z= z[:-1]\n",
    "        q= q[:-1]\n",
    "    elif np.isnan(x[-1]) or np.isnan(y[-1]) or np.isnan(z[-1]) or np.isnan(q[-1]):\n",
    "        x = x[:-1]\n",
    "        y= y[:-1]\n",
    "        z= z[:-1]\n",
    "        q= q[:-1]\n",
    "#     print(np.std(ecg_min),np.std(y_test_min),np.std(y_pred_min),np.median(qual_min))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,spearmanr\n",
    "q,x,y,z = np.array(q),np.array(x),np.array(y),np.array(z)\n",
    "for i in np.linspace(0,.9,10):\n",
    "    index = np.where((q>=i)&(q<=i+.1))[0]\n",
    "    if len(index)<2:\n",
    "        continue\n",
    "    print(pearsonr(x[index],y[index]),pearsonr(y[index],z[index]),i,i+.1,len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(y.reshape(-1),50)\n",
    "plt.hist(y_pred.reshape(-1),50)\n",
    "plt.hist(ecg_test.reshape(-1),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y[0].reshape(1,-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred1[1].reshape(-1),means_test.reshape(-1),'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(y_pred1[1].reshape(-1),means_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[np.isfinite(t)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(quals_test.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
